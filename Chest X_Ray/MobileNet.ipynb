{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq4uVtPUI4ifDeZtzMIhUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/CNN/blob/main/Chest%20X_Ray/MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas tensorflow\n",
        "# !pip install seaborn"
      ],
      "metadata": {
        "id": "OTGajOP5MYzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install latex\n",
        "# !sudo apt-get update -y\n",
        "# !sudo apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng cm-super"
      ],
      "metadata": {
        "id": "8IWMqQKH22LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tf-slim"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9UKbA0eXpz1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your data directory path and image size\n",
        "data_dir = \"/content/drive/MyDrive/Chest X_Ray\"\n",
        "mobilenet_input_size = (224, 224)  # Image size for MobileNetV2\n",
        "\n",
        "# Load and resize image\n",
        "def load_image(directory, cls, img_file):\n",
        "    img_path = os.path.join(directory, cls, img_file)\n",
        "    img = Image.open(img_path).resize(mobilenet_input_size)\n",
        "    return img\n",
        "\n",
        "# Prepare data\n",
        "X, y = [], []\n",
        "label_map = {cls: idx for idx, cls in enumerate(os.listdir(data_dir)) if os.path.isdir(os.path.join(data_dir, cls))}\n",
        "\n",
        "for cls in label_map.keys():\n",
        "    cls_dir = os.path.join(data_dir, cls)\n",
        "    for img_file in os.listdir(cls_dir):\n",
        "        img_path = os.path.join(cls_dir, img_file)\n",
        "        img = load_img(img_path, target_size=mobilenet_input_size)\n",
        "        img_array = img_to_array(img)\n",
        "        X.append(img_array)\n",
        "        y.append(label_map[cls])\n",
        "\n",
        "X = np.array(X).astype('float32') / 255.0\n",
        "y = np.array(y).astype('int')\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=22)\n",
        "\n",
        "# Define MobileNetV2 model\n",
        "def build_mobilenetv2(input_shape, num_classes):\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Build and compile model\n",
        "input_shape = (mobilenet_input_size[0], mobilenet_input_size[1], 3)\n",
        "num_classes = len(label_map)\n",
        "model = build_mobilenetv2(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Predict on training and test data\n",
        "train_predictions = model.predict(X_train)\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "train_predictions = np.argmax(train_predictions, axis=1)\n",
        "test_predictions = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Compute confusion matrices\n",
        "cm_train = confusion_matrix(y_train, train_predictions)\n",
        "cm_test = confusion_matrix(y_test, test_predictions)\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_confusion_matrices(cm_train, cm_test, class_names, filename='confusion_matrices.png'):\n",
        "    plt.rcParams.update({\n",
        "        \"text.usetex\": True,\n",
        "        \"font.family\": \"serif\",\n",
        "        \"font.serif\": [\"Computer Modern Roman\"],\n",
        "    })\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    sns.heatmap(cm_train, annot=True, fmt='d', ax=axes[0], cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=False, annot_kws={\"size\": 16})\n",
        "    axes[0].set_title('Training Confusion Matrix', fontsize=16)\n",
        "    axes[0].set_xlabel('Predicted labels', fontsize=14)\n",
        "    axes[0].set_ylabel('True labels', fontsize=14)\n",
        "    sns.heatmap(cm_test, annot=True, fmt='d', ax=axes[1], cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=False, annot_kws={\"size\": 16})\n",
        "    axes[1].set_title('Testing Confusion Matrix', fontsize=16)\n",
        "    axes[1].set_xlabel('Predicted labels', fontsize=14)\n",
        "    axes[1].set_ylabel('True labels', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "plot_confusion_matrices(cm_train, cm_test, list(label_map.keys()), filename='confusion_matrices.png')\n",
        "\n",
        "# Plot convergence curves\n",
        "def plot_convergence_curves(history, filename='convergence_curves.png'):\n",
        "    plt.rcParams.update({\n",
        "        \"text.usetex\": True,\n",
        "        \"font.family\": \"serif\",\n",
        "        \"font.serif\": [\"Computer Modern Roman\"],\n",
        "    })\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Accuracy Convergence', fontsize=16)\n",
        "    ax1.set_xlabel('Epoch', fontsize=14)\n",
        "    ax1.set_ylabel('Accuracy', fontsize=14)\n",
        "    ax1.legend()\n",
        "    ax1.grid()\n",
        "    ax2.plot(history.history['loss'], label='Train Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Loss Convergence', fontsize=16)\n",
        "    ax2.set_xlabel('Epoch', fontsize=14)\n",
        "    ax2.set_ylabel('Loss', fontsize=14)\n",
        "    ax2.legend()\n",
        "    ax2.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "plot_convergence_curves(history, filename='convergence_curves.png')\n",
        "\n",
        "# Calculate metrics for the training set\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
        "train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
        "train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
        "\n",
        "# Calculate metrics for the testing set\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Create a DataFrame to display metrics as a table\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "    'Training': [train_accuracy, train_precision, train_recall, train_f1],\n",
        "    'Testing': [test_accuracy, test_precision, test_recall, test_f1]\n",
        "})\n",
        "\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "id": "vnf4G1Rvzjqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}