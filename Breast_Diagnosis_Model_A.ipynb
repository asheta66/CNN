{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlub6QRSzSDael9Kq2Hmv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/CNN/blob/main/Breast_Diagnosis_Model_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTGajOP5MYzp",
        "outputId": "968379ea-4aa6-4024-a8bf-8b936496d34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ryfM-39wKsBL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "71446fb6-9f0e-4398-d5da-e9f73873ead6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/data2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4f258a32268b>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Get the list of class names (subfolders)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Resize the image sizes to different resolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/data2'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "# 1. Mount data from Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your data directory path\n",
        "data_dir = '/content/drive/My Drive/data2'\n",
        "\n",
        "# Get the list of class names (subfolders)\n",
        "classes = [cls for cls in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, cls))]\n",
        "\n",
        "# Resize the image sizes to different resolutions\n",
        "resolutions = [(32, 32), (64, 64), (128, 128), (227, 227), (300,300)]\n",
        "\n",
        "# Function to resize images\n",
        "def resize_images(directory, size):\n",
        "    for cls in classes:\n",
        "        cls_dir = os.path.join(directory, cls)\n",
        "        for img_file in os.listdir(cls_dir):\n",
        "            img_path = os.path.join(cls_dir, img_file)\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                img = img.resize(size)\n",
        "                img.save(img_path)  # overwrite original image with resized image\n",
        "            except (IOError, UnidentifiedImageError):\n",
        "                print(f\"Could not process file {img_path}\")\n",
        "\n",
        "# Function to build and compile the CNN model\n",
        "def build_compile_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy', precision, recall, f1_score])\n",
        "    return model\n",
        "\n",
        "# Custom metrics\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "    return recall\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
        "\n",
        "def plot_confusion_matrices(cm_train, cm_test, classes, train_title, test_title, filename, font_size=10):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
        "\n",
        "    # Training confusion matrix\n",
        "    ax[0].imshow(cm_train, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax[0].set_title(train_title, fontsize=font_size)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    ax[0].set_xticks(tick_marks)\n",
        "    ax[0].set_yticks(tick_marks)\n",
        "    ax[0].set_xticklabels(classes, rotation=45, fontsize=font_size)\n",
        "    ax[0].set_yticklabels(classes, fontsize=font_size)\n",
        "    fmt = 'd'\n",
        "    thresh = cm_train.max() / 2.\n",
        "    for i, j in itertools.product(range(cm_train.shape[0]), range(cm_train.shape[1])):\n",
        "        ax[0].text(j, i, format(cm_train[i, j], fmt),\n",
        "                   horizontalalignment=\"center\",\n",
        "                   color=\"white\" if cm_train[i, j] > thresh else \"black\",\n",
        "                   fontsize=font_size)\n",
        "    ax[0].set_ylabel('True label', fontsize=font_size)\n",
        "    ax[0].set_xlabel('Predicted label', fontsize=font_size)\n",
        "    ax[0].grid(False)\n",
        "\n",
        "    # Testing confusion matrix\n",
        "    ax[1].imshow(cm_test, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax[1].set_title(test_title, fontsize=font_size)\n",
        "    ax[1].set_xticks(tick_marks)\n",
        "    ax[1].set_yticks(tick_marks)\n",
        "    ax[1].set_xticklabels(classes, rotation=45, fontsize=font_size)\n",
        "    ax[1].set_yticklabels(classes, fontsize=font_size)\n",
        "    fmt = 'd'\n",
        "    thresh = cm_test.max() / 2.\n",
        "    for i, j in itertools.product(range(cm_test.shape[0]), range(cm_test.shape[1])):\n",
        "        ax[1].text(j, i, format(cm_test[i, j], fmt),\n",
        "                   horizontalalignment=\"center\",\n",
        "                   color=\"white\" if cm_test[i, j] > thresh else \"black\",\n",
        "                   fontsize=font_size)\n",
        "    ax[1].set_ylabel('True label', fontsize=font_size)\n",
        "    ax[1].set_xlabel('Predicted label', fontsize=font_size)\n",
        "    ax[1].grid(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.show()\n",
        "\n",
        "# Function to draw subplots for each class at different resolutions\n",
        "def plot_class_resolutions(data_dir, classes, resolutions):\n",
        "    fig, axes = plt.subplots(len(classes), len(resolutions), figsize=(12,12))\n",
        "\n",
        "    # Iterate over each class\n",
        "    for class_idx, cls in enumerate(classes):\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "        img_files = os.listdir(cls_dir)\n",
        "        random_img_file = random.choice(img_files)  # Randomly select an image from the class\n",
        "\n",
        "        # Iterate over each resolution\n",
        "        for res_idx, resolution in enumerate(resolutions):\n",
        "            img = load_resized_image(data_dir, cls, random_img_file, resolution)\n",
        "\n",
        "            # Plot the image in the corresponding subplot\n",
        "            ax = axes[class_idx, res_idx]\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')  # Hide axes ticks\n",
        "            if class_idx == 0:\n",
        "                ax.set_title(f'{resolution[0]}x{resolution[1]}', fontsize=11)  # Set resolution as title for the top row\n",
        "            if res_idx == 0:\n",
        "                ax.set_ylabel(cls, fontsize=11)  # Set class name as y-label for the first column\n",
        "\n",
        "    # Adjust layout and show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_resolutions.png')\n",
        "    plt.show()\n",
        "\n",
        "# Function to resize and load a single image\n",
        "def load_resized_image(directory, cls, img_file, size):\n",
        "    img_path = os.path.join(directory, cls, img_file)\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize(size)\n",
        "    return img\n",
        "\n",
        "# Lists to store results\n",
        "histories = []\n",
        "confusion_matrices_train = []\n",
        "confusion_matrices_test = []\n",
        "classification_reports_train = []\n",
        "classification_reports_test = []\n",
        "\n",
        "# Run the model 5 times with different resolutions\n",
        "for resolution in resolutions:\n",
        "    print(f\"Running model with resolution {resolution}...\")\n",
        "\n",
        "    # Resize images\n",
        "    resize_images(data_dir, size=resolution)\n",
        "\n",
        "    # Prepare data\n",
        "    X, y = [], []\n",
        "    label_map = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "        for img_file in os.listdir(cls_dir):\n",
        "            img_path = os.path.join(cls_dir, img_file)\n",
        "            img = load_img(img_path)\n",
        "            img_array = img_to_array(img)\n",
        "            X.append(img_array)\n",
        "            y.append(label_map[cls])\n",
        "\n",
        "    X = np.array(X).astype('float32') / 255.0\n",
        "    y = np.array(y).astype('int')\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=23)\n",
        "\n",
        "    # Build and compile model\n",
        "    model = build_compile_model(input_shape=(resolution[0], resolution[1], 3), num_classes=len(classes))\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Save history\n",
        "    histories.append(history)\n",
        "\n",
        "    # Compute confusion matrices\n",
        "    train_predictions = np.argmax(model.predict(X_train), axis=1)\n",
        "    test_predictions = np.argmax(model.predict(X_test), axis=1)\n",
        "    cm_train = confusion_matrix(y_train, train_predictions)\n",
        "    cm_test = confusion_matrix(y_test, test_predictions)\n",
        "    confusion_matrices_train.append(cm_train)\n",
        "    confusion_matrices_test.append(cm_test)\n",
        "\n",
        "    # Compute classification reports\n",
        "    train_report = classification_report(y_train, train_predictions, target_names=classes, output_dict=True)\n",
        "    test_report = classification_report(y_test, test_predictions, target_names=classes, output_dict=True)\n",
        "    classification_reports_train.append(train_report)\n",
        "    classification_reports_test.append(test_report)\n",
        "\n",
        "    # Plot confusion matrices with increased font size\n",
        "    plot_confusion_matrices(cm_train, cm_test, classes, f'Training Confusion Matrix - {resolution}', f'Testing Confusion Matrix - {resolution}', f'confusion_matrices_{resolution}.png', font_size=14)\n",
        "\n",
        "    # Plot convergence curves (accuracy and loss in one figure as subplots)\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5))\n",
        "\n",
        "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.set_title(f'Accuracy - {resolution}')\n",
        "    ax1.grid()\n",
        "\n",
        "    ax2.plot(history.history['loss'], label='Train Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.set_title(f'Loss - {resolution}')\n",
        "    ax2.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'convergence_curve_{resolution}.png')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a summary table for all cases\n",
        "summary_table = pd.DataFrame(columns=['Resolution', 'Train Accuracy', 'Test Accuracy', 'Train Precision', 'Test Precision', 'Train Recall', 'Test Recall', 'Train F1', 'Test F1'])\n",
        "\n",
        "for i, resolution in enumerate(resolutions):\n",
        "    train_accuracy = histories[i].history['accuracy'][-1]\n",
        "    test_accuracy = histories[i].history['val_accuracy'][-1]\n",
        "    train_precision = classification_reports_train[i]['weighted avg']['precision']\n",
        "    test_precision = classification_reports_test[i]['weighted avg']['precision']\n",
        "    train_recall = classification_reports_train[i]['weighted avg']['recall']\n",
        "    test_recall = classification_reports_test[i]['weighted avg']['recall']\n",
        "    train_f1 = classification_reports_train[i]['weighted avg']['f1-score']\n",
        "    test_f1 = classification_reports_test[i]['weighted avg']['f1-score']\n",
        "\n",
        "    summary_table = pd.concat([summary_table, pd.DataFrame({\n",
        "        'Resolution': [resolution],\n",
        "        'Train Accuracy': [train_accuracy],\n",
        "        'Test Accuracy': [test_accuracy],\n",
        "        'Train Precision': [train_precision],\n",
        "        'Test Precision': [test_precision],\n",
        "        'Train Recall': [train_recall],\n",
        "        'Test Recall': [test_recall],\n",
        "        'Train F1': [train_f1],\n",
        "        'Test F1': [test_f1]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "# Show summary table\n",
        "display(summary_table)\n",
        "summary_table.to_csv('summary_table.csv', index=False)"
      ],
      "metadata": {
        "id": "5K4rMytL08Nw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}