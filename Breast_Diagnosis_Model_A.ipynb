{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPehGwWj8SykbNRmM0Td7rT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/CNN/blob/main/Breast_Diagnosis_Model_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y pandas tensorflow\n",
        "# !pip install pandas tensorflow\n",
        "# !pip install seaborn\n"
      ],
      "metadata": {
        "id": "OTGajOP5MYzp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latex\n",
        "# !sudo apt-get update -y\n",
        "# !sudo apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng cm-super"
      ],
      "metadata": {
        "id": "8IWMqQKH22LA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your data directory path and resolution options\n",
        "data_dir = '/content/drive/My Drive/data2'\n",
        "resolution_options = {\n",
        "    '32x32': (32, 32),\n",
        "    '56x56': (56, 56),\n",
        "    '128x128': (128, 128),\n",
        "    '256x256': (256, 256),\n",
        "    '512x512': (512, 512)\n",
        "}\n",
        "\n",
        "# Select a resolution\n",
        "print(\"\\nSelect the resolution:\")\n",
        "for i, (res_name, res_size) in enumerate(resolution_options.items(), 1):\n",
        "    print(f\"{i}. {res_name}\")\n",
        "print(\"\")\n",
        "selection_index = int(input(\"Enter the number corresponding to your choice: \")) - 1\n",
        "\n",
        "# Validate the selection\n",
        "if selection_index < 0 or selection_index >= len(resolution_options):\n",
        "    raise ValueError(\"Invalid selection. Exiting.\")\n",
        "\n",
        "# Set the selected resolution and data directory\n",
        "selected_resolution_name = list(resolution_options.keys())[selection_index]\n",
        "selected_resolution_size = resolution_options[selected_resolution_name]\n",
        "data_dir = os.path.join(data_dir, selected_resolution_name)\n",
        "\n",
        "# Check if the data directory exists\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(f\"Directory '{data_dir}' does not exist.\")\n",
        "\n",
        "# Get class names (subfolders)\n",
        "classes = [cls for cls in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, cls))]\n",
        "\n",
        "# Display number of images per class\n",
        "for cls in classes:\n",
        "    num_images = len(os.listdir(os.path.join(data_dir, cls)))\n",
        "    print(f\"Class '{cls}': {num_images} images\")\n",
        "\n",
        "# Build and compile the CNN model\n",
        "def build_compile_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Load a single image\n",
        "def load_image(directory, cls, img_file):\n",
        "    img_path = os.path.join(directory, cls, img_file)\n",
        "    img = Image.open(img_path)\n",
        "    return img\n",
        "\n",
        "# Prepare data\n",
        "X, y = [], []\n",
        "label_map = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(data_dir, cls)\n",
        "    for img_file in os.listdir(cls_dir):\n",
        "        img_path = os.path.join(cls_dir, img_file)\n",
        "        img = load_img(img_path, target_size=selected_resolution_size)\n",
        "        img_array = img_to_array(img)\n",
        "        X.append(img_array)\n",
        "        y.append(label_map[cls])\n",
        "\n",
        "X = np.array(X).astype('float32') / 255.0\n",
        "y = np.array(y).astype('int')\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=22)\n",
        "\n",
        "# Build and compile model\n",
        "input_shape = (selected_resolution_size[0], selected_resolution_size[1], 3)\n",
        "num_classes = len(classes)\n",
        "model = build_compile_model(input_shape, num_classes)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))\n",
        "\n",
        "# Initialize a list to store metrics for saving\n",
        "metrics = []\n",
        "\n",
        "# Predict and evaluate\n",
        "train_predictions = np.argmax(model.predict(X_train), axis=1)\n",
        "test_predictions = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Compute metrics for training data\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
        "train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
        "train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
        "\n",
        "# Store training metrics in the list\n",
        "metrics.append({\n",
        "    'Dataset': 'Training',\n",
        "    'Resolution': f'{selected_resolution_size[0]}x{selected_resolution_size[1]}',\n",
        "    'Accuracy': train_accuracy,\n",
        "    'Precision': train_precision,\n",
        "    'Recall': train_recall,\n",
        "    'F1 Score': train_f1\n",
        "})\n",
        "\n",
        "# Compute metrics for testing data\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Store testing metrics in the list\n",
        "metrics.append({\n",
        "    'Dataset': 'Testing',\n",
        "    'Resolution': f'{selected_resolution_size[0]}x{selected_resolution_size[1]}',\n",
        "    'Accuracy': test_accuracy,\n",
        "    'Precision': test_precision,\n",
        "    'Recall': test_recall,\n",
        "    'F1 Score': test_f1\n",
        "})\n",
        "\n",
        "# Create a DataFrame from the metrics list\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Display metrics DataFrame\n",
        "print(metrics_df)\n",
        "\n",
        "# Define filename with resolution\n",
        "excel_filename = f'performance_metrics_{selected_resolution_size[0]}x{selected_resolution_size[1]}.xlsx'\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "metrics_df.to_excel(excel_filename, index=False, sheet_name='Performance Metrics')\n",
        "\n",
        "print(f\"Metrics saved to {excel_filename}\")\n",
        "\n",
        "# Save the CNN architecture as a PNG figure\n",
        "plot_model(model, to_file=f'model_architecture_{selected_resolution_size[0]}x{selected_resolution_size[1]}.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnf4G1Rvzjqm",
        "outputId": "6f741441-f27e-4ec8-8ddb-4ac4fa0623ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Select the resolution:\n",
            "1. 32x32\n",
            "2. 56x56\n",
            "3. 128x128\n",
            "4. 256x256\n",
            "5. 512x512\n",
            "\n",
            "Enter the number corresponding to your choice: 5\n",
            "Class 'malignant': 360 images\n",
            "Class 'benign': 537 images\n",
            "Class 'normal': 133 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot confusion matrices\n",
        "def plot_confusion_matrices(cm_train, cm_test, class_names, filename='confusion_matrices.png'):\n",
        "    plt.rcParams.update({\n",
        "        \"text.usetex\": True,\n",
        "        \"font.family\": \"serif\",\n",
        "        \"font.serif\": [\"Computer Modern Roman\"],\n",
        "    })\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
        "    sns.heatmap(cm_train, annot=True, fmt='d', ax=axes[0], cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=False, annot_kws={\"size\": 16})\n",
        "    axes[0].set_title('Training Confusion Matrix', fontsize=16)\n",
        "    axes[0].set_xlabel('Predicted labels', fontsize=14)\n",
        "    axes[0].set_ylabel('True labels', fontsize=14)\n",
        "    sns.heatmap(cm_test, annot=True, fmt='d', ax=axes[1], cmap='Blues', xticklabels=class_names, yticklabels=class_names, cbar=False, annot_kws={\"size\": 16})\n",
        "    axes[1].set_title('Testing Confusion Matrix', fontsize=16)\n",
        "    axes[1].set_xlabel('Predicted labels', fontsize=14)\n",
        "    axes[1].set_ylabel('True labels', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Assuming `cm_train` and `cm_test` are already computed\n",
        "cm_train = confusion_matrix(y_train, train_predictions)\n",
        "cm_test = confusion_matrix(y_test, test_predictions)\n",
        "plot_confusion_matrices(cm_train, cm_test, classes, filename=f'confusion_matrices_{selected_resolution_size[0]}x{selected_resolution_size[1]}.png')\n",
        "\n",
        "# Plot convergence curves\n",
        "def plot_convergence_curves(history, filename='convergence_curves.png'):\n",
        "    plt.rcParams.update({\n",
        "        \"text.usetex\": True,\n",
        "        \"font.family\": \"serif\",\n",
        "        \"font.serif\": [\"Computer Modern Roman\"],\n",
        "    })\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Accuracy Convergence', fontsize=16)\n",
        "    ax1.set_xlabel('Epoch', fontsize=14)\n",
        "    ax1.set_ylabel('Accuracy', fontsize=14)\n",
        "    ax1.legend()\n",
        "    ax1.grid()\n",
        "    ax2.plot(history.history['loss'], label='Train Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Loss Convergence', fontsize=16)\n",
        "    ax2.set_xlabel('Epoch', fontsize=14)\n",
        "    ax2.set_ylabel('Loss', fontsize=14)\n",
        "    ax2.legend()\n",
        "    ax2.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Assuming `history` is already computed\n",
        "plot_convergence_curves(history, filename=f'convergence_curves_{selected_resolution_size[0]}x{selected_resolution_size[1]}.png')\n"
      ],
      "metadata": {
        "id": "U93bV7AK8l50"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}