{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvoe6ugDCg+sH7d+Y4Cqfq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/CNN/blob/main/Breast_Diagnosis_Model_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y pandas tensorflow\n",
        "# !pip install pandas tensorflow"
      ],
      "metadata": {
        "id": "OTGajOP5MYzp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your data directory path\n",
        "data_dir = '/content/drive/My Drive/data2'\n",
        "\n",
        "# Define possible resolution options and corresponding folder names\n",
        "resolutionOptions = {\n",
        "    '32x32': (32, 32),\n",
        "    '56x56': (56, 56),\n",
        "    '128x128': (128, 128),\n",
        "    '256x256': (256, 256),\n",
        "    '512x512': (512, 512)\n",
        "}\n",
        "\n",
        "# Ask the user to select a resolution\n",
        "print(\"\\nSelect the resolution:\")\n",
        "for i, (res_name, res_size) in enumerate(resolutionOptions.items(), 1):\n",
        "    print(f\"{i}. {res_name}\")\n",
        "print(\"\")\n",
        "\n",
        "selectionIndex = int(input(\"Enter the number corresponding to your choice: \")) - 1\n",
        "if selectionIndex < 0 or selectionIndex >= len(resolutionOptions):\n",
        "    raise ValueError(\"Invalid selection. Exiting.\")\n",
        "\n",
        "# Construct the data directory path and resolution based on the selected resolution\n",
        "selectedResolutionName = list(resolutionOptions.keys())[selectionIndex]\n",
        "selectedResolutionSize = resolutionOptions[selectedResolutionName]\n",
        "data_dir = os.path.join('/content/drive/My Drive/data2', selectedResolutionName)\n",
        "\n",
        "# Display the selected directory path and resolution\n",
        "print(f\"\\nSelected data directory: {data_dir}\")\n",
        "print(f\"Selected resolution: {selectedResolutionSize}\\n\")\n",
        "\n",
        "# Check if the data directory exists\n",
        "if not os.path.exists(data_dir):\n",
        "    raise FileNotFoundError(f\"Directory '{data_dir}' does not exist.\")\n",
        "\n",
        "# Get the list of class names (subfolders)\n",
        "classes = [cls for cls in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, cls))]\n",
        "\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(data_dir, cls)\n",
        "    num_images = len(os.listdir(cls_dir))\n",
        "    print(f\"Class '{cls}': {num_images} images\")\n",
        "\n",
        "# Function to build and compile the CNN model\n",
        "def build_compile_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])  # Ensure 'accuracy' is used\n",
        "    return model\n",
        "\n",
        "# Function to load a single image\n",
        "def load_image(directory, cls, img_file):\n",
        "    img_path = os.path.join(directory, cls, img_file)\n",
        "    img = Image.open(img_path)\n",
        "    return img\n",
        "\n",
        "# Prepare data\n",
        "X, y = [], []\n",
        "label_map = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(data_dir, cls)\n",
        "    img_files = os.listdir(cls_dir)\n",
        "\n",
        "    for img_file in img_files:\n",
        "        img_path = os.path.join(cls_dir, img_file)\n",
        "        img = load_img(img_path, target_size=selectedResolutionSize)\n",
        "        img_array = img_to_array(img)\n",
        "        X.append(img_array)\n",
        "        y.append(label_map[cls])\n",
        "\n",
        "X = np.array(X).astype('float32') / 255.0\n",
        "y = np.array(y).astype('int')\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=22)\n",
        "\n",
        "input_shape = (selectedResolutionSize[0], selectedResolutionSize[1], 3)\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Build and compile model\n",
        "model = build_compile_model(input_shape, num_classes)\n",
        "\n",
        "# Train the model with validation split\n",
        "history = model.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test))\n",
        "\n",
        "# Predict and evaluate\n",
        "y_train_pred = np.argmax(model.predict(X_train), axis=1)\n",
        "y_test_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "report_train = classification_report(y_train, y_train_pred, target_names=classes)\n",
        "report_test = classification_report(y_test, y_test_pred, target_names=classes)\n",
        "\n",
        "# Save the CNN architecture as a PNG figure\n",
        "plot_model(model, to_file=f'model_architecture_{selectedResolutionSize[0]}x{selectedResolutionSize[1]}.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Draw a sample image (one image from each class)\n",
        "fig, axes = plt.subplots(1, len(classes), figsize=(10, 10))\n",
        "for ax, cls in zip(axes, classes):\n",
        "    img_file = random.choice(os.listdir(os.path.join(data_dir, cls)))\n",
        "    img = load_image(data_dir, cls, img_file)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(cls)\n",
        "    ax.axis('off')\n"
      ],
      "metadata": {
        "id": "NTLhBhBRT2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2093df18-6e3d-431b-9f30-66bb96caff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Select the resolution:\n",
            "1. 32x32\n",
            "2. 56x56\n",
            "3. 128x128\n",
            "4. 256x256\n",
            "5. 512x512\n",
            "\n",
            "Enter the number corresponding to your choice: 1\n",
            "\n",
            "Selected data directory: /content/drive/My Drive/data2/32x32\n",
            "Selected resolution: (32, 32)\n",
            "\n",
            "Class 'benign': 437 images\n",
            "Class 'malignant': 210 images\n",
            "Class 'normal': 133 images\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "Exception ignored in: <function AtomicFunction.__del__ at 0x7d36f0841630>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 302, in __del__\n",
            "    self._bound_context.remove_function(self.name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1530, in remove_function\n",
            "    pywrap_tfe.TFE_ContextRemoveFunction(self._handle, name)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5575 - loss: 0.9905 - val_accuracy: 0.5577 - val_loss: 0.9458\n",
            "Epoch 2/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5817 - loss: 0.9397 - val_accuracy: 0.6090 - val_loss: 0.9035\n",
            "Epoch 3/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5977 - loss: 0.9045 - val_accuracy: 0.6410 - val_loss: 0.8523\n",
            "Epoch 4/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6275 - loss: 0.8763 - val_accuracy: 0.6346 - val_loss: 0.8373\n",
            "Epoch 5/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6443 - loss: 0.8730 - val_accuracy: 0.6603 - val_loss: 0.8095\n",
            "Epoch 6/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6301 - loss: 0.8174 - val_accuracy: 0.6795 - val_loss: 0.7864\n",
            "Epoch 7/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6487 - loss: 0.7678 - val_accuracy: 0.6667 - val_loss: 0.7636\n",
            "Epoch 8/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.6505 - loss: 0.7507 - val_accuracy: 0.6667 - val_loss: 0.7536\n",
            "Epoch 9/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6671 - loss: 0.7375 - val_accuracy: 0.6667 - val_loss: 0.7305\n",
            "Epoch 10/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6725 - loss: 0.7245 - val_accuracy: 0.6603 - val_loss: 0.7523\n",
            "Epoch 11/25\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7028 - loss: 0.6861 - val_accuracy: 0.6987 - val_loss: 0.6995\n",
            "Epoch 12/25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the figure\n",
        "plt.savefig(f'sample_images_{selectedResolutionSize[0]}x{selectedResolutionSize[1]}.png')\n",
        "plt.close()\n",
        "\n",
        "# Save confusion matrices\n",
        "plot_confusion_matrices(cm_train, cm_test, classes,\n",
        "                        train_title='Training Confusion Matrix',\n",
        "                        test_title='Testing Confusion Matrix',\n",
        "                        filename=f'confusion_matrices_{selectedResolutionSize[0]}x{selectedResolutionSize[1]}.png',\n",
        "                        font_size=8)  # Reduce font size for clarity\n",
        "\n",
        "# Plot convergence curves (accuracy and loss in one figure as subplots) and save as PNG\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 5))  # Adjusted figsize\n",
        "\n",
        "# Plot metrics\n",
        "def plot_metric(metric_name, ax, title, ylabel):\n",
        "    if metric_name in history.history:\n",
        "        ax.plot(history.history[metric_name], label='Train ' + title)\n",
        "    if f'val_{metric_name}' in history.history:\n",
        "        ax.plot(history.history[f'val_{metric_name}'], label='Validation ' + title)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.legend()\n",
        "    ax.set_title(f'{title} - {selectedResolutionName}')\n",
        "    ax.grid()\n",
        "\n",
        "# Accuracy plot\n",
        "plot_metric('accuracy', ax1, 'Accuracy', 'Accuracy')\n",
        "\n",
        "# Loss plot\n",
        "plot_metric('loss', ax2, 'Loss', 'Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'convergence_curve_{selectedResolutionName}.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fqUgYtgZOz8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store metrics for saving\n",
        "metrics = []\n",
        "\n",
        "# After training and predictions\n",
        "train_predictions = np.argmax(model.predict(X_train), axis=1)\n",
        "test_predictions = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Compute metrics for training data\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
        "train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
        "train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
        "\n",
        "# Store training metrics in the list\n",
        "metrics.append({\n",
        "    'Dataset': 'Training',\n",
        "    'Resolution': f'{selectedResolutionSize[0]}x{selectedResolutionSize[1]}',\n",
        "    'Accuracy': train_accuracy,\n",
        "    'Precision': train_precision,\n",
        "    'Recall': train_recall,\n",
        "    'F1 Score': train_f1\n",
        "})\n",
        "\n",
        "# Compute metrics for testing data\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "# Store testing metrics in the list\n",
        "metrics.append({\n",
        "    'Dataset': 'Testing',\n",
        "    'Resolution': f'{selectedResolutionSize[0]}x{selectedResolutionSize[1]}',\n",
        "    'Accuracy': test_accuracy,\n",
        "    'Precision': test_precision,\n",
        "    'Recall': test_recall,\n",
        "    'F1 Score': test_f1\n",
        "})\n",
        "\n",
        "# Create a DataFrame from the metrics list\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Display metrics DataFrame\n",
        "print(metrics_df)\n",
        "\n",
        "# Define filename with resolution\n",
        "excel_filename = f'performance_metrics_{selectedResolutionSize[0]}x{selectedResolutionSize[1]}.xlsx'\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "metrics_df.to_excel(excel_filename, index=False, sheet_name='Performance Metrics')\n",
        "\n",
        "print(f\"Metrics saved to {excel_filename}\")\n"
      ],
      "metadata": {
        "id": "skPcN7klO4ud"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}